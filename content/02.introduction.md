## Introduction

When do two identifiers indicate the same thing? Linking the same or related entities at scale is crucial
for knowledge base and ontology integration. For example, if two different disease databases, one with
information about disease genes and the other with information about disease symptoms, are to be merged,
then it is important to precisely know which disease in one database corresponds to which disease in the other.


A common method to automate ontology matching is to use lexical methods, in particular matching
on primary or alternative labels that have been assigned to concepts, sometimes in combination with
lexical normalization. These can often provide very high recall, but low precision, due to lexical ambiguity.
Examples are provided in @tbl:example-matches, including a false match between an aeroplane part and an
insect part due to sharing the same name (wing) based on analogous function.


| Resource A       | Concept A | Resource B          | Concept B       | Predicted    | True Predicate |
|------------------|-----------|---------------------|-----------------|--------------|---------------|
| UK Auto Ontology | Car       | Industrial Ontology | Automobile      | n/a          | `exactMatch`  |
| Train Ontology   | Car       | Industrial Ontology | RailwayCarriage | n/a          | `closeMatch` |
| Fly ontology     | Wing      | Industrial ontology | Wing            | `exactMatch` | `differentFrom` |

Table: Example of entity matching problem
{#tbl:example-matches}

An example of this approach is the LOOM algorithm used in the Bioportal ontology
resource, which provides very high recall, including NNN mappings across over a thousand vocabularies.

A number of approaches can give higher precision mappings, many of these make use of other relationships
or properties in the ontology. The Ontology Alignment Evaluation Initiative (OAEI) provides a yearly
evaluation of different methods for ontology matching. One of the top-performing methods in OAEI is the LogMap
tool, which makes use of logical axioms in the ontology to assist in mapping.

A number of tools such as LogMap been used to build or link ontologies and knowledge bases. However,
these approaches are usually used in conjunction with manual curation of mappings, which can be
resource intensive.

Deep learning approaches and in particular Language Models (LMs) have been applied to ontology matching tasks.
Some methods make use of embedding distance OntoEmma, e.g [Wang
et al., 2018], DeepAlignment [Kolyvakis et al., 2018],
VeeAlign [Iyer et al., 2020]. More recently the Truveta Mapper [@doi:10.48550/arXiv.2301.09767] 
treats matching as a Translation task and involves pre-training on ontology structures.

The most recent development in LMs are so-called Large Language Models (LLMs), exemplified by ChatGPT,
which involved billions of parameters and pre-training on instruction-prompting tasks. The resulting
models have generalizable abilities to perform a wide range of tasks, including question answering,
information extraction. However, one challenge with LLMs is the problem of *hallucination*.

One possibility is using GPT to generate mappings de-novo. However, the problem of hallucination makes this
highly unreliable, in particular, due to the propensity for LLMs to hallucinate database or ontology identifiers
when these are requested.

We devised an alternative approach called *MapperGPT* that does not use GPT to generate mappings de-novo, but instead works in
concert with existing high-recall methods such as LOOM. We use GPT to refine and predict relationships
(predicates) as a post-processing step. We use an in-context knowledge-driven semantic approach, in
which examples of different mapping categories are provided, and information about the two concepts in a mapping
is provided.

We evaluated this on a series of alignment tasks from different domains, including anatomy, developmental
biology, and renal diseases. We devised a collection of tasks that are designed to be particularly challenging
for lexical methods. We show that when used in combination with high-recall methods such as LOOM or LexMatch,
MapperGPT can provide a substantial improvement in accuracy beating SOTA methods such as LogMap.

Our contributions are as follows:

- creation of a series of new matching tasks expressed using the SSSOM standard
- An algorithm and tool MapperGPT that uses GPT to predict relationships between concepts

